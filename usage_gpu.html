<!doctype html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="keywords" content="">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover">
	<link rel="canonical" href="https://paragroup.github.io/WindFlow/usage_gpu.html">
    <link rel="shortcut icon" type="image/png" href="favicon.png">
    
	<link rel="stylesheet" type="text/css" href="./css/bootstrap.min.css?2254">
	<link rel="stylesheet" type="text/css" href="style.css?4200">
	<link rel="stylesheet" type="text/css" href="./css/prism.css?6975">
	
	
    <title>Usage_GPU</title>


    
<!-- Analytics -->
 
<!-- Analytics END -->
    
</head>
<body>

<!-- Preloader -->
<div id="page-loading-blocs-notifaction" class="page-preloader"></div>
<!-- Preloader END -->


<!-- Main container -->
<div class="page-container">
    
<!-- bloc-0 -->
<div class="bloc l-bloc " id="bloc-0">
	<div class="container bloc-sm">
		<div class="row">
			<div class="col">
				<nav class="navbar navbar-light row navbar-expand-md" role="navigation">
					<a class="navbar-brand" href="index.html">WindFlow</a>
					<button id="nav-toggle" type="button" class="ml-auto ui-navbar-toggler navbar-toggler border-0 p-0" data-toggle="collapse" data-target=".navbar-48557" aria-expanded="false" aria-label="Toggle navigation">
						<span class="navbar-toggler-icon"><svg height="32" viewBox="0 0 32 32" width="32"><path class="svg-menu-icon " d="m2 9h28m-28 7h28m-28 7h28"></path></svg></span>
					</button>
					<div class="collapse navbar-collapse navbar-48557">
							<ul class="site-navigation nav navbar-nav ml-auto">
								<li class="nav-item">
									<a href="index.html" class="btn btn-lg btn-glossy btn-c-4866">Home</a>
								</li>
								<li>
									<a href="operators.html" class="btn btn-lg btn-glossy btn-c-4866">Operators</a>
								</li>
								<li>
									<a href="usage.html" class="btn btn-lg btn-glossy btn-c-4866">API<br></a>
								</li>
								<li>
									<a href="usage_gpu.html" class="btn btn-lg btn-glossy btn-c-4866">API GPU</a>
								</li>
								<li>
									<a href="kafka.html" class="btn btn-lg btn-glossy btn-c-4866">API Kafka<br></a>
								</li>
								<li>
									<a href="rocksdb.html" class="btn btn-lg btn-glossy btn-c-4866">API RocksDB<br></a>
								</li>
								<li>
									<a href="dashboard.html" class="btn btn-lg btn-glossy btn-c-4866">Dashboard</a>
								</li>
								<li>
									<a href="https://github.com/ParaGroup/WindFlow/archive/refs/tags/v4.0.0.zip" class="btn btn-lg btn-glossy btn-c-4866">Download</a>
								</li>
								<li>
									<a href="about.html" class="btn btn-lg btn-glossy btn-c-4866">About</a>
								</li>
							</ul>
						</div>
				</nav>
			</div>
		</div>
	</div>
</div>
<!-- bloc-0 END -->

<!-- bloc-1 -->
<div class="bloc none l-bloc" id="bloc-1">
	<div class="container bloc-no-padding">
		<div class="row bgc-4866">
			<div class="order-md-0 col-md-12 col-lg-6 order-lg-1 offset-lg-1">
				<picture><source type="image/webp" srcset="img/logo_white.webp"><img src="img/logo_white.png" class="img-fluid img-style float-lg-none" alt="logo_white" width="500" height="310"></picture>
			</div>
			<div class="align-self-center offset-md-1 col-md-10 col-lg-4 col-sm-10 offset-sm-1 col-10 offset-1">
				<h4 class="mg-md tc-6038 btn-resize-mode h2-style float-lg-right">
					A C++17 Data Stream Processing Parallel Library for Multicores and GPUs&nbsp;<br>
				</h4>
			</div>
		</div>
	</div>
</div>
<!-- bloc-1 END -->

<!-- bloc-5 -->
<div class="bloc tc-5711 l-bloc" id="bloc-5">
	<div class="container bloc-lg">
		<div class="row">
			<div class="col">
				<h2 class="mg-md tc-3327">
					<strong>GPU API Example</strong><br>
				</h2>
				<div>
					<script src="js/prism.js"></script>
					
				</div>
				<p class="text-justify">
						WindFlow, starting from version 3.0, supports some operators targeting NVIDIA GPUs.&nbsp;Two of them are Maps and Filters. In this page, we show how to use them in a simple example representing the skeleton of a <strong>FraudDetection</strong> application processing credit card transactions (see the&nbsp;<a class="ltc-4866" href="https://github.com/GMAP/DSPBench">DSPBench</a>&nbsp;benchmark suite [1] for further information). The application is composed of four operators, two of them offloaded on GPU. The Source is in charge of producing a stream of transactions from an input dataset (already parsed for simplicity). The Filter is in charge of dropping all the empty transactions present in the input stream. The Map operator processes all the transactions belonging to the same customer in order to add a boolean flag stating whether the transaction is classified as a potential fraud or not. Finally, the Sink receives results with their classification flag.<br><br>The logical data-flow graph of the application is reported below. WindFlow allows the use of GPU devices for <strong>general-purpose stateful stream processing</strong>. This is a shift with respect to the state of the art. Indeed, GPUs are traditionally used to accelerate specific data analytics tasks which apply associative functions on input batches (e.g., reduceByKey of Apache Spark). But, letâ€™s address this point step by step.
					</p><picture><source type="image/webp" srcset="img/lazyload-ph.png" data-srcset="img/application_gpu.webp"><img src="img/lazyload-ph.png" data-src="img/application_gpu.jpg" class="img-fluid mx-auto d-block mg-md img-application-g-style lazyload" alt="application_gpu" width="600" height="106"></picture>
				<p class="text-justify">
						GPU operators come with some additional constraints to be used. In particular, the input and output types, as well as the key attribute type (if any), must be <strong>trivially copyable</strong> from host-accessible memory to GPU-accessible memory. Below, we define the data type used by the operators.
					</p>
				<div>
						<pre><code class="language-cpp">
#define MAX_LEN_RECORD 256

struct record_t
{
    int customer_id // identifies the customer
    char record[MAX_LEN_RECORD]; // contains the transaction id and the transaction type
    bool isFraud; // true if the record is classified as a fraud, false otherwise
};
</code></pre>
						
					</div>
				<p class="text-justify">
							The Source operator is in charge of producing a stream of objects of this type by reading a large sequence of transactions from an already prepared vector.
						</p>
				<div>
							<pre><code class="language-cpp">
class Source_Functor
{
private:
	std::vector&lt;record_t&gt; records; // contains the transactions

public:
	// Constructor
    Source_Functor(const std::vector&lt;record_t&gt; &_records):
                   records(_records) {}

	// Functor logic
	void operator()(wf::Source_Shipper&lt;record_t&gt; &shipper)
	{
    	// generation loop
    	for (auto record: records) {
    		record_t output(record);
    		shipper.push(output);
    	}
	}
};
</code></pre>
							
						</div>
				<p>
								The first operator is a <strong>Filter_GPU</strong> instance using the functional logic defined by the functor object below. The operator applies the functor logic on each input and retains all the inputs for which the predicate is <i>true</i>.
							</p>
				<div>
								<pre><code class="language-cpp">
class Filter_Functor
{
public:
	// Functor logic
    __device__ bool operator()(record_t &input)
    {
    	if ((input.record)[0] == '\0')
    		return false;
    	else
    		return true;
    }  
}
</code></pre>
								
							</div>
				<p class="text-justify">
									The <strong>Map_GPU</strong> operator is configured to work on a keyby manner. This means that all inputs having the same key (in this case the <i>customer_id</i> field) will be processed sequentially, while parallelism is exploited between records belonging to different customers. The API allows GPU operators created with a key extractor to use a state object maintained on GPU memory for each key (and always accessed sequentially by the active CUDA threads). The fragment below shows the definition of the functional logic of the Map_GPU, where the classification code is abstracted from brevity.
								</p>
				<div>
									<pre><code class="language-cpp">
class Map_Functor
{
public:
	...
	// Functor logic
    __device__ void operator()(record_t &input, PredictionModel &model)
    {
    	model.add_record(input);
    	input.isFraud = model.updateClassification();
    }
}

class PredictionModel
{
private:
	... // member variables and functions
private:
	// Constructor (default construtor is required!)
	__device__ PredictionModel() {...}

	// Destructor
	__device__ ~PredictionMode(...) {...}
	
	// add a new record to the model
	__device__ void addRecord(record_t &record) {...}
	
	// evaluate the classification
	__device__ bool updateClassification() {...}
};
</code></pre>
									
								</div>
				<p class="text-justify">
										The run-time system guarantees that the update to the prediction model for each customer will be done sequentially, one by one. Therefore, WindFlow allows &nbsp;GPUs to be used for stateful stream processing using the common keyby paradigm. This approach is quite general and useful for a broad set of real-world applications. Of course, in case of associative functions, other operators on GPU can be used (e.g., Reduce_GPU and FFAT_Windows_GPU not shown in this example).<br><br>To conclude to showcase the API, operators are created with a very high-level user-friendly interface.
									</p>
				<div>
										<pre><code class="language-cpp">
Source_Functor source_functor(records);
wf::Source source = wf::Source_Builder(source_functor)
                		.withParallelism(1)
                		.withName("wc_source")
                		.withOutputBatchSize(1000)
                		.build();

Filter_Functor filter_functor;
wf::Filter_GPU filter_gpu = wf::FilterGPU_Builder(filter_functor)
                	   			.withParallelism(2)
                				.withName("filter_gpu")
                				.build();

Map_Functor map_functor;
wf::Map_GPU map_gpu = wf::MapGPU_Builder(map_functor)
              	  			.withParallelism(2)
                			.withName("map_gpu")
                			.withKeyBy([] __host__ __device__ (const record_t &record) -> int { return record.customer_id; })
                			.build();

Sink_Functor sink_functor;
wf::Sink sink = wf::Sink_Builder(sink_functor)
                	.withParallelism(3)
                	.withName("sink")
                	.build();

wf::PipeGraph topology("fraudprediction", Execution_Mode_t::DEFAULT, Time_Policy_t::INGRESS_TIME);
topology.add_source(source).add(filter_gpu).add(map_gpu).add_sink(sink);
topology.run(); // synchronous execution of the dataflow
</code></pre>
										
									</div>
				<h2 class="tc-5711 mg-md">
											<strong>Important Aspects</strong>
										</h2>
				<p class="text-justify">
											The use of GPU operators requires special care. In the code above, the batch size is set during the creation of the first operator preceding a sequence of GPU operators. In this case, the Source defines a batch size of 1000 tuples composing each batch. Batches of 1000 inputs are processed by the Filter_GPU, and each one is delivered to the following Map_GPU operator (now the batch can contain less than 1000 inputs depending on the filtering predicate). Choosing the right batch size, as well the parallelism level of the operators, requires manual tuning by the user to achieve the highest performance as possible.<br>
										</p>
				<h2 class="mg-md tc-5711">
											<strong>References</strong>
										</h2>
				<div>
											<ol>
<li> M. V. Bordin, D. Griebler, G. Mencagli, Claudio F. R. Geyer, Luiz G. L. Fernandes. DSPBench: a Suite of Benchmark Applications for Distributed Data Stream Processing Systems. IEEE Access, 2020, IEEE. ISSN: 2169-3536, DOI: 10.1109/ACCESS.2020.3043948
</li></ol>
											
										</div>
			</div>
		</div>
	</div>
</div>
<!-- bloc-5 END -->

<!-- ScrollToTop Button -->
<button aria-label="Scroll to top button" class="bloc-button btn btn-d scrollToTop" onclick="scrollToTarget('1',this)"><svg xmlns="http://www.w3.org/2000/svg" width="22" height="22" viewBox="0 0 32 32"><path class="scroll-to-top-btn-icon" d="M30,22.656l-14-13-14,13"/></svg></button>
<!-- ScrollToTop Button END-->


<!-- bloc-8 -->
<div class="bloc l-bloc" id="bloc-8">
	<div class="container bloc-lg">
		<div class="row">
			<div class="col-md-3 col-sm-6">
				<h4 class="mg-md text-sm-left text-center">
					About
				</h4><a href="http://calvados.di.unipi.it/paragroup/" class="a-btn a-block footer-link ltc-4866">PPMs Group</a><a href="https://www.unipi.it/" class="a-btn a-block footer-link ltc-4866">University of Pisa</a>
			</div>
			<div class="col-md-3 col-sm-6">
				<h4 class="mg-md text-sm-left text-center">
					<br>
				</h4><a href="index.html" class="a-btn a-block footer-link"></a><a href="index.html" class="a-btn a-block footer-link"><br></a>
			</div>
			<div class="col-md-3 col-sm-6">
				<h4 class="mg-md text-sm-left text-center">
					<br>
				</h4><a href="index.html" class="a-btn a-block footer-link"><br></a><a href="index.html" class="a-btn a-block footer-link"></a>
			</div>
			<div class="col-md-3 col-sm-6">
				<h4 class="mg-md text-sm-left text-center">
					Get the library
				</h4><a href="https://github.com/ParaGroup/WindFlow/archive/refs/tags/4.2.0.zip" class="a-btn a-block footer-link ltc-4866">Download</a><a href="https://github.com/ParaGroup/WindFlow" class="a-btn a-block footer-link ltc-4866">GitHub</a>
			</div>
		</div>
	</div>
</div>
<!-- bloc-8 END -->

</div>
<!-- Main container END -->
    


<!-- Additional JS -->
<script src="./js/jquery.min.js?4355"></script>
<script src="./js/bootstrap.bundle.min.js?2609"></script>
<script src="./js/blocs.min.js?9298"></script>
<script src="./js/lazysizes.min.js" defer></script>
<script src="./js/prism.js?9690"></script><!-- Additional JS END -->


</body>
</html>
